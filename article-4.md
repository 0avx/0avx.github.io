# TPM Pitfalls in Anti-Cheat Systems

## Introduction
Before getting into the interesting parts of this article, we need a refresher on how TPM trust works and why it matters for anti-cheat systems. I also must mention that this article was not written to explain TPM in detail, as many articles already exist for that purpose, and while I do recap things that must be understood, I wrote this article to go over various pitfalls that anti-cheats may face when implementing TPM security, which I have not seen discussed before.
To start, we have to understand that a TPM begins with Several Roots of Trust (ROT) that form a foundation, such as the Root of Trust for Measurement (RTM), which performs the first measurements at boot, the Root of Trust for Reporting (RTR), and the Root of Trust for Storage (RTS). “[A RoT is trusted always to behave in the expected manner, because its misbehavior cannot be detected (such as by measurement) by attestation or observation.](https://trustedcomputinggroup.org/wp-content/uploads/TCG_Roots_of_Trust_Specification_v0p20_PUBLIC_REVIEW.pdf)”

One key TPM mechanism is the Platform Configuration Registers (PCR). Ignoring platform-specific PCR resets, PCRs can only be changed through a hardware-enforced “extend” operation. "[other than reset, described above, the only way to change a PCR value is to Extend it. The Extend operation on a PCR is defined as PCRnew = Halg(PCRold || digest)](https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-1-Version-184_pub.pdf).” The platform spec (TCG UEFI PC client) defines what gets measured into which PCRs and requires a measured boot event log. Because the log can be replayed and rehashed, any tampering becomes detectable when the final PCR values no longer match what the TPM reports.

The TPM also contains an Endorsement Key (EK), a unique restricted decryption-only (recommended in TPM 2.0) key pair, derived by the Endorsement Primary Seed (EPS). By itself, the EK is just a key; “[Unless the EK is certified by a trusted entity, its trust and privacy properties are no different from any other asymmetric key that can be generated by pure software methods. Therefore, by itself, the public portion of the EK is not privacy sensitive.](https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-0-Version-184_pub.pdf)” “[An Attestation Key (AK) is a particular type of signing key that has a restriction on its use, in order to prevent forgery (the signing of external data that has the same format as genuine attestation data). The restriction is that an AK can be used only to sign a digest that the TPM has created. If an AK is known to be protected by a TPM (by virtue of attestation of type 3 or 4), it can be relied on to report accurately on Shielded Location content, and not sign externally provided data that appears to be valid and TPM-produced but is not.](https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-0-Version-184_pub.pdf)” The AK is the key used for signing attestation data, because using the EK for signing would reveal a user’s unique hardware identity, because as said before, it is uniquely tied to a specific TPM. Trust in the AK can be established through credential activation, where the server encrypts a challenge to be decrypted by the EK and binds it to the AK, and only a genuine TPM with the EK private key (EKPriv) can decrypt it, and this proves the AK is resident on a genuine TPM. Technically, anyone can generate and import their own keys into the TPM, where they know the private key, but a proper AK is supposed to have attributes that defend against such an attack.

For this article, trust means something that cannot be forged in software. A software-only anti-cheat, even running in kernel mode, shares the same environment as an attacker. Its checks can be patched, its memory manipulated, and its network protocol perfectly emulated. An attacker can reverse engineer the anti-cheat, reproduce every packet it sends, and present zero anomalies to the server, because afterall, its code is executing in an untrusted environment. But even if the networking and behavior of the anti-cheat are flawlessly emulated, the attacker still cannot emulate a trusted TPM. They can reproduce the TPM command set, but they cannot reproduce which TPM it came from, or a manufacturer-signed EKCert. The difference is not in behavior but in origin, meaning that the trust comes because the manufacturer vouches for this given TPM, and if it’s vouched for, an attesting authority knows that the EKPriv is tucked away securely.

Normally, privacy-preserving attestation hides the EK, so that verifiers know an AK is genuine without knowing which TPM produced it. The TPM model intentionally avoids revealing identity. But anti-cheat systems often want a stable, non-spoofable hardware identity. So instead of relying on privacy-preserving attestation, the anti-cheat will use the EK, and after confirming that the TPM is trusted, and that the AK is on said trusted TPM, then it will know that anything signed by the AK is trusted too, while also having a manufacturer-backed hardware identity.

## Real-World Firmware Issues
Recall that an EK is just an asymmetric key pair, and a TPM is just a chip following a specification. Neither has any inherent meaning unless someone vouches for them, which as we said before, comes from the EKCert, and only after verifying this certificate does the EK become part of the trusted reporting chain.

So what happens when a system does not send an EKCert at all? In theory, the attestation should simply be rejected, right? Because without an EKCert, the server cannot verify that the EK came from a real TPM rather than software emulation, and the entire trust collapses because for all they know, the EK given is attacker controlled and isn’t tied to a real TPM at all. 

In practice, anti-cheats must support an enormous variety of consumer hardware, firmware revisions, motherboard vendors, and other various implementations. Corporate attestation systems can assume clean, uniform fleets, while anti-cheats cannot, and this is where hardware errata becomes unavoidable, and why unlike in corporate environments where the EKPub can be used to enforce stricter trust requirements, an anti-cheat must trust as many genuine TPMs as possible, and depend on the EKCert for trust.

Below are examples published by FACEIT, and AMD, outlining a known firmware issue affecting certain AMD and Intel fTPM versions:

![](https://i.imgur.com/qyrkJWY.png)

These specific firmware ranges shipped with broken or missing EKCerts. To my knowledge, they did not publish why there was an issue with the EKCert on these firmwares, or if it was revoked at all, but AMD and Intel eventually released corrected firmware to motherboard manufacturers, but not every vendor pushed updates to their customer base, which I can assume is because they were scared of breaking Bitlocker configurations as outlined in the screenshot. As a result, there are still systems in the wild whose TPMs do technically still function, but cannot provide a valid EKCert, causing attestation to fail even though the device is otherwise legitimate.

From an anti-cheat perspective, this creates an uncomfortable situation. Normally missing EKCerts mean the attestation is untrustworthy, but because these edge cases exist, what does an anti-cheat do? Reject them like FACEIT? While this may be feasible for FACEIT due to their smaller user base, what do you do on an anti-cheat used for way more players like Vanguard, EasyAntiCheat, BattlEye, or Javelin? You either reject the TPM, not allowing these players to play at all, or blindly trust the EK, which breaks the trust hierarchy entirely, because now the EK can be controlled entirely by an attacker, allowing them to generate entirely fabricated attestation reports, because they now know the EKPriv, and thus can activate their AK, and sign whatever they want with it.

## The Limits with Consumer Environments
Even if EKCerts are handled correctly, RTM presents additional challenges for anti-cheat use. According to the TCG specification, the CRTM must be immutable and trusted. If this initial code can be altered, then any subsequent measurement chain can be forged without detection, because the mechanism responsible for detecting tampering is itself compromised, and as per the spec, it is not up to the TPM to ensure that these have not been tampered with, as it is assuming whatever it is fed is trusted. This is why hardware security features exist, because for it to actually be trusted, there must be cryptographic proof that the first code to execute on the CPU has not been modified in any way possible, and hopefully, is locked from modification in the first place.

In tightly managed environments, such as enterprise systems, these protections are often enabled and enforced. The CRTM is locked down, firmware updates are authenticated, and the measurement chain begins from a known, immutable state. Because the platform is controlled, they can maintain known-good measurements, “[A Reference Integrity Manifest contains data such as expected PCR values or expected measurements that a Verifier uses to validate expected values (Assertions) against actual values (Evidence),](https://trustedcomputinggroup.org/wp-content/uploads/TCG-Guidance-on-Integrity-Measurements-and-Event-Log-Processing-Version-1.0-RC-1_24February25.pdf)” and verify the boot log and PCRs with high confidence, and if any security feature becomes disabled, or any other abnormality is detected, they can block access accordingly. Consumer gaming systems do not offer this predictability, because OEMs usually have many security features disabled by default, and SPI flash may be unlocked entirely, thus allowing the CRTM to be modified without detection.

Furthermore, for anti-cheats, there is no Reference Integrity Manifest, and a deviation in a PCR, or the measured boot log, cannot be directly interpreted as malicious, because there is nothing concrete to compare it against in the first place. People have self-signed bootloaders, people patch their firmware, motherboard manufacturers may not post their firmware updates publicly right away, and instead only distribute them through specialized applications, and this unpredictability makes it difficult for an anti-cheat. Now, anti-cheats can observe when a driver is measured from an unexpected location, when certain measurements appear statistically rare across the population, or for specific measurements that appear in specific cheats. Large-scale telemetry helps identify outliers, and can even be used to detect firmware patches, and other cheat-created abnormalities because cheaters are statistical outliers, but it cannot substitute for a true hardware-backed known-good root. The underlying problem is structural: the RTM offers strong guarantees only when the CRTM is immutable and the platform is controlled. Consumer hardware rarely meets these requirements, and even if it is starting now, older machines with valid TPMs may still not.

## Closing Words
I hope that this article will be useful for anti-cheat companies implementing TPM security, or technical enthusiasts wanting to know more about what caveats that an anti-cheat may be dealing with to get around it, and that a TPM alone is not the silver bullet. Other attack vectors, such as the cuckoo attack, where you proxy TPM commands to another genuine TPM with a trusted attestation log, are still difficult to reliably detect, because an anti-cheat is trusting of any TPM, as long as it is vouched for by a valid EKCert. The spec also outlines that “[The Platform Certificate is assurance from the certifying authority of the physical binding between the platform (the RTM) and the RTR.](https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-0-Version-184_pub.pdf)” This ensures that a specific TPM identity is attached to a specific motherboard, preventing it from being extracted, but in an anti-cheat’s case, it is not useful. After all, if an anti-cheat allows use of a dTPM, and an attacker just wants to change their fingerprint, they can purchase and swap it out for pretty cheap. Generally, if a fTPM is found to be available for a given system, then that attack can be made more costly by enforcing it. Even if an anti-cheat attempts to verify that the measured boot log came from the system that they’re running on by comparing events to what is present on the system in the kernel, the underlying code doing those checks is untrusted, and can be patched freely, or emulated entirely.
